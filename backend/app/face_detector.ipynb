{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "!Powershell.exe -Command Invoke-WebRequest -Uri \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\" -OutFile \"../resources/detector.tflite\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:21:24.703730Z",
     "start_time": "2024-01-10T00:21:20.163225400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89BlskiiyGDC"
   },
   "source": [
    "## Visualization utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLHhoIkkWYLQ"
   },
   "source": [
    "To better demonstrate the Face Detector API, we have created a set of visualization tools that will be used in this colab. These will draw a bounding box around detected faces, as well as markers over certain detected points on the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "H4aPO-hvbw3r",
    "ExecuteTime": {
     "end_time": "2024-01-10T00:22:12.220716100Z",
     "start_time": "2024-01-10T00:22:12.214766100Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "ROW_SIZE = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "TEXT_COLOR = (255, 0, 0)  # red\n",
    "\n",
    "\n",
    "def _normalized_to_pixel_coordinates(\n",
    "    normalized_x: float, normalized_y: float, image_width: int,\n",
    "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
    "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
    "\n",
    "  # Checks if the float value is between 0 and 1.\n",
    "  def is_valid_normalized_value(value: float) -> bool:\n",
    "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
    "                                                      math.isclose(1, value))\n",
    "\n",
    "  if not (is_valid_normalized_value(normalized_x) and\n",
    "          is_valid_normalized_value(normalized_y)):\n",
    "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
    "    return None\n",
    "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
    "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
    "  return x_px, y_px\n",
    "\n",
    "\n",
    "def visualize(\n",
    "    image,\n",
    "    detection_result\n",
    ") -> np.ndarray:\n",
    "  \"\"\"Draws bounding boxes and keypoints on the input image and return it.\n",
    "  Args:\n",
    "    image: The input RGB image.\n",
    "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
    "  Returns:\n",
    "    Image with bounding boxes.\n",
    "  \"\"\"\n",
    "  annotated_image = image.copy()\n",
    "  height, width, _ = image.shape\n",
    "\n",
    "  for detection in detection_result.detections:\n",
    "    # Draw bounding_box\n",
    "    bbox = detection.bounding_box\n",
    "    start_point = bbox.origin_x, bbox.origin_y\n",
    "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
    "    cv2.rectangle(annotated_image, start_point, end_point, TEXT_COLOR, 3)\n",
    "\n",
    "    # Draw keypoints\n",
    "    for keypoint in detection.keypoints:\n",
    "      keypoint_px = _normalized_to_pixel_coordinates(keypoint.x, keypoint.y,\n",
    "                                                     width, height)\n",
    "      color, thickness, radius = (0, 255, 0), 2, 2\n",
    "      cv2.circle(annotated_image, keypoint_px, thickness, color, radius)\n",
    "\n",
    "    # Draw label and score\n",
    "    category = detection.categories[0]\n",
    "    category_name = category.category_name\n",
    "    category_name = '' if category_name is None else category_name\n",
    "    probability = round(category.score, 2)\n",
    "    result_text = category_name + ' (' + str(probability) + ')'\n",
    "    text_location = (MARGIN + bbox.origin_x,\n",
    "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
    "    cv2.putText(annotated_image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83PEJNp9yPBU"
   },
   "source": [
    "## Download test image\n",
    "\n",
    "To demonstrate Face Detection, you can download a sample image using the following code. Credits: https://pixabay.com/photos/brother-sister-girl-family-boy-977170/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "!Powershell.exe -Command Invoke-WebRequest -Uri \"https://i.imgur.com/Vu2Nqwb.jpg\" -OutFile \"../resources/image.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T00:20:51.358219900Z",
     "start_time": "2024-01-10T00:20:50.204368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tzXuqyIBlXer",
    "ExecuteTime": {
     "end_time": "2024-01-10T00:22:29.807324500Z",
     "start_time": "2024-01-10T00:22:27.808065800Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = '../resources/image.jpg'\n",
    "\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "img = cv2.imread(IMAGE_FILE)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy4r2_ePylIa"
   },
   "source": [
    "## Running inference and visualizing the results\n",
    "\n",
    "The final step is to run face detection on your selected image. This involves creating your FaceDetector object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
    "\n",
    "You can check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector/python) to learn more about configuration options that this solution supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Yl_Oiye4mUuo",
    "ExecuteTime": {
     "end_time": "2024-01-10T00:22:35.275280400Z",
     "start_time": "2024-01-10T00:22:32.822750900Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an FaceDetector object.\n",
    "base_options = python.BaseOptions(model_asset_path='../resources/detector.tflite')\n",
    "options = vision.FaceDetectorOptions(base_options=base_options)\n",
    "detector = vision.FaceDetector.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(IMAGE_FILE)\n",
    "\n",
    "# STEP 4: Detect faces in the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "image_copy = np.copy(image.numpy_view())\n",
    "annotated_image = visualize(image_copy, detection_result)\n",
    "rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('Image', rgb_annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNJq-ygtZX7J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
